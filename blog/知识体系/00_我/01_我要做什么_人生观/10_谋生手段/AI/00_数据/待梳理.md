——

对产品经理的工作启示  

业务！数据！

**新鲜的数据和能持续产生新鲜数据的业务，是一个大模型的生命力所在。**

一个 RAG 做的再牛逼，如果数据库很糟糕，结果就是很糟糕的。一个模型再挫，只要数据足够好，照样是一个好工具。在 AI 时代，数据的问题只会被放的更大，AI 搜索如果在一堆屎山数据里面做搜索，充其量不过是又造了一根搅屎棍。

**任何时候，能持续生产真实交易数据和优秀内容的业务都比大模型本身重要。**

避免 FOMO，**少看论文多动手**

我认为一个比较清晰的事实是，目前工业界短期内一定高估了大模型的作用。前段时间我写了一个段子：每一个 App 都值得思考是否能用 AI 重做一遍，然后就会发现值得重做的只有 10%。

短期内的资源投入很大程度上是源自于投资人和大厂决策者的 FOMO 心态，这种心态某种角度来说是不健康的。这种 FOMO 的心态也会传导给产品经理，于是很多产品经理都开始看论文（比如本文作者），但在我看来产品经理看论文其实没什么用，图一乐的作用更大。

**论文都是锤子，但是对于 PM 来说更重要的是钉子在哪里。**

所以，与其关心最新的学术界又发了什么，不如关心一下 Product Hunt 上面哪些 AI 产品又登上了当日第一，并且赚钱了。

**与其 FOMO，不如动手多用用，以前移动互联网刚刚兴起的时候，大部分产品经理手机里面不得装小几百个 App，天天研究来研究去的。去用一下市面上最好的应用，并且尝试逆向它，会有多很收获。**

**写这篇文章，写接近 2 万字，发现大模型那么多的坑，而且每个坑都能找到一些关联的论文。不是因为闲的蛋疼去看论文，而是因为一直在捣鼓 AI，然后发现这也有问题那也有问题，不得已去搜索，搜到了论文。**

原来大家都有这个问题，有的人就是有钻研精神，发现了问题还会深入研究，然后写一篇论文。哎，人比人真的气死人。

**如果仔细看就会发现我看的大部分论文都是工程师论文而不是算法论文，因为就像我强调的，大模型的弱点需要工程弥补，工程是研发和产品经理共同搭建的，看不懂算法的论文不打紧，看不懂工程师的论文可能真的得反思一下。**

——

2015 年，我正在听 Thomas Mikolov 谈论 word2vec...他并没有将其解释为算法创新...他将其描述为类似～“我想简化架构，这样我就可以将更多数据塞入其中它比其他任何人都具有超快的 C 实现”

2016 年，在牛津大学攻读博士学位的第一天，我第一次与导师会面时，我的导师让我坐下来，说道：“安德鲁——每个人都想从事模型研究——但真正推动该领域向前发展的工 作是更大/更好数据集。”

三年后 - 2019 年，“LLMs 不起作用”和“天哪 GPT-1 正在做某事”之间的区别是一个非常干净的训练数据集（主要是 Reddit），OpenAI 已经开发出来，其他人没有

Transformer 已经问世约 2 年了 - GPT-1 论文中的主要创新是 OpenAI 的数据清理工作。

老实说，从那时起 - 我开始相信最大的乘数是越来越多（更干净的）数据 - 通常使用性感的人工智能名称进行包装，这有点分散了对相同基本概念的注意力：

- RLHF：雇用人员来制作更好的数据
- InstructGPT：雇用人员来制作更好的数据
- 蒸馏：使用模型创建更清晰的数据子集
- （OpenAI 和其他公司最近收购的大量数据集）：购买人们已经制作的更好的数据
- ...

很难比较进步——但我认为过去几年的主要驱动力绝对是 NVIDIA + 更多数据（不仅仅是算法/即时工程/等），这是完全合理的。

为什么“更大的模型”很有趣？这是因为我们有更多的数据可以填充它们。如果没有更多数据，更大的模型就会过度拟合。

为什么更大的计算很有趣？ — 这样我们就可以制作更大的模型 — 这样我们就可以将更多数据装入其中。

为什么 Transformer（一种更简单的架构）击败了 LSTM？我们可以更容易地将它们扩展到更大的数据集

为什么 word2vec 击败了之前的 RNN？...更多数据

为什么GPT-1会引发最新的AI浪潮？...更多/更干净的数据

始终是数据

它可能会继续与数据有关

——

AI
绝不可能是把海量数据直接丢给AI直接生成指标，而是：
一则可以让AI生成规则，然后基于规则使用BI系统计算出需要的指标，
二则可以让AI基于部分数据和业务目标，给予推荐的衡量指标和计算公式（指标是需要对比、参照物的，没有对比的数据没有含义（参考雷军发布会的碰瓷对比））

——
所谓的“前沿数据”是指那些与应用场景密切相关、能及时反映最新趋势和变化的数据，往往包含大量长尾或少见的场景，有助于提升AI在非典型情况下的表现，推动人工智能能力的边界向复杂推理、多模态等方向发展。
