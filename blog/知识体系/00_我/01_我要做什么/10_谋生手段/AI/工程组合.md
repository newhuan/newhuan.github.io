每一个离线任务都可以考虑用模型来解决

——

当然具体是用 Python 库还是用大模型，其实是取决于成本和效果的考量，这个也需要通过实验来证明。

我自己的经验是这种数据清洗的工作适合用 Python 库做一轮，再用大模型做一轮清洗，效果可能会更好，但是很多时候 Python 库已经足够干净了，中间夹杂一些错误的格式编码其实也不影响后续大模型的判断，这种情况下做不做都是无所谓的。

总而言之大模型在特定环节的工作能力是非常强的，如果不是考虑成本，其实几乎每个环节都可以用大模型解决。

成本和效果要做 Trade off

众所周知，大模型回答有一定的随机性，要怎么解决这个问题呢？当然是一个问题重复问几遍。

——

论文《From Local to Global: A Graph RAG Approach to Query-Focused

——

把任务拆小拆细、避免互相影响

把一个复杂问题拆成多个简单问题，然后再让模型处理有两个好处：

第一、正如上文所描述，大模型的不稳定性和它接权的文本规模大小完全是呈正相关的，如果把问题拆小就意味着单次任务模型要处理的文本变少。

第二、一些简单的问题根本没必要用大模型，甚至可以用简单的模型或者是纯逻辑去判断。更便宜、速度更快，甚至效果可能会更好。

区分离线任务和在线任务

以 Grpah RAG 架构为例子，它一共分为三个步骤：

1. 将待搜索的知识进行一个三元组抽取（主谓宾），这个抽取的动作需要 LLM 介入，存入图数据库中（可离线处理）；

2. 将用户提出来的关键词，用 LLM 做一次扩散，扩散出来同义词，近义词等，然后在图数据库进行检索，找到相关文档（必须是在线服务）；

3. 将查询出来的相关内容作为上下文，和用户提出的问题一起交给大模型来生成内容（必须是在线服务）；

其中前两个步骤是离线任务，离线任务意味着可以花费较多的时间对数据做精细化的处理，比如我们可以用一个开源但是性能强悍的大模型，用自己的服务器去跑任务，以此来在保证质量的时候降低成本。

而在线任务则意味着需要较强的时效性，如果在线任务本身复杂度并不高，也可以选择更加轻量级的模型来保证回复速度。同时离线任务的结果会被存储并且反复调用，用质量更好的模型相当
为 n8n 不是从这一轮 AI 浪潮才开始做的，所以它的生态也比这一轮 AI 后才涌现出的 Workflow 工具（比如 Dify）更完善，官方接入的集成服务更多，社区更活跃。

n8n 就是大模型的五官、躯干和四肢，动手又动脑，才能有创造。在这里我推荐一个 n8n 的中文教程《简单易懂的现代魔法》，这应该是目前市面上最好的 n8n 中文教程。

教程地址：https://n8n.akashio.com/

——

Agent、微调、提示词之间的边界与最佳实践

如果我们把提示词工程、Agent 的建设和模型微调对应到我们给一个人布置任务，就可以这么理解。

- 提示词工程相当于你在布置任务的时候说的很详细。
- Agent 建设相当于你给这个人布置任务的时候，把 SOP 拆清楚，并且告诉他公司里面有哪些工具可以用。
- 模型微调相当于做培训。

所以完成一个任务，可能三种手段都需要用上，但是三种手段的成本是不一样的。而为了完成一个任务，应该用哪种优化手段，这就是目前工程、算法、产品、学者这几方面都非常模糊的地方，这个就好像是在航海或者挖矿，又像是临床医学，怎么决定用什么手段，本质上是一个「实验」，而不是一个「推理」。

这也就是为什么上面列出来的每一篇论文都需要列非常多的基准测试，因为设计这些 Agent 的人自己都不知道结果到底好不好，需要实验才能验证。

所以我认为，未来哪个团队应用 AI 的能力强，哪个团队应用 AI 的能力弱，其实就取决于：

- 这个团队有没有牛逼的基准测试参考答案；
- 这个团队能不能有一个平台可以更快的验证自己的设计是不是合理的；
  - 快速验证想法是否准确（飞轮效应）


谁实验做得快，谁就牛逼，工程化产品化反而是最后一步。

最后我个人建议是能不要微调，就不要微调，因为微调会改变模型的参数层，成本很高而且无法迁移。而且微调的本质是在和大模型团队卷算力、卷数据，内卷在长期来看，是没有意义的。

——

所以如果你把 AI 视作为一个又一个不知疲倦的实习生，你认为他们能干嘛？当然是设计好 SOP 和产出物标准，让他们去做这些量大且重复性的工作啦。

