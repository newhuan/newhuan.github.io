Intel作为车上的驾驶员，掌握着制订游戏规则的权力，而Intel制订的游戏规则就是它自己的产品CPU作为“中央”处理器，通过PCIe扩展的形式，让围绕CPU的整个计算机系统变得非常具有可扩展性，可以围绕CPU打造各行各业的解决方案。而这套游戏规则的残酷之处在于，一旦一种PCIe设备的需求变得稳定，Intel就在CPU里增加一些专用指令，于是这种PCIe设备就从历史长河中抹去了，这种方式消失的各类PCIe扩展卡不计其数，显卡在这套游戏规则下也并不例外。

生态竞争的残酷实际上是运动员和裁判的竞争。任何一种新兴需求都有潜力催生一些新的生态位，但游戏规则的定制者会建立一套让自己立于不败之地的规则。生态竞争需要台下的nobody构造一个在这样一个体系内打造并守住独立生态位的战略。这个说实话，没有可复制的路径，不同时间节点下标准化体系的形态是完全不一致的，不同的需求和生态位对生态亲和性的要求，包括可以借力的点也是完全不一致的。

如果没有老黄对于这场竞争深刻的洞察力，以及相应的战略，显卡也一样会消失在历史的长河中。老黄当时意识到这个问题后，提出了Intel的摩尔定律是十八个月翻一番，NVidia要做到六个月翻一番。用更快的性能提升曲线快速拉高需求，让Intel的集显变成落后的产品。于是NVidia把显卡越做越大，功耗越做越高，性能拉升的幅度也远超Intel，从而让游戏画质提升飞快，导致Intel的集显疲于去追NVidia的节奏，面积和功耗各方面都承受巨大的压力。最终，独立显卡在Intel的游戏规则下成为了事实标准，NVidia也卡住了游戏卡这个不大不小的生态位。

但老黄这套竞争逻辑，其实没有直接借鉴的可能性，今天显卡的生态位早成为事实标准中的一环。我们即使学会了怎么在Intel的规则下打Intel也没有什么意义了，因为时过境迁，今天制订规则的变成了NVidia，实际上每个屠龙少年都会成为新的恶龙，他们的成功也同时堵死了对应生态位的后来者。今天要争取的是AI这个需求。老黄这套打法背后的思想，才是真正值得借鉴的，但如何因地制宜在现如今的情形下用好，也是极具挑战性的。

生态竞争最有效的路线是生态位的竞争。实际上同一个生态位内的竞争只存在两种可能性：一种是生态位建立的初期，新兴的需求催生了新的生态位，但这个生态位的赢家还没出现时，无数玩家会下场去竞争这个生态位。但最终往往会决胜出一两家，一旦稳定下来之后基本是没有什么机会的。另外一种就是神仙打架了，整个标准化体系内有无数大大小小的生态位，每个生态位也会和周边的生态位有千丝万缕的联系。一个拥有更大生态位的裁判可以借着生态位的影响力去侵入其他稍弱一些的生态位，扩张自己的地盘，比如今天ARM联合苹果和NVidia去侵蚀x86的生态位。但这两条路实际上都不适合今天我们这些nobody。

其实NVidia的第二段壮举向我们展示了另外一种更加有效的生态竞争方式。NVidia并不是靠差异化的CPU去和Intel竞争的，而是靠把GPGPU的生态位在数据中心的价值占比越做越大实现的。这个过程实际上是不同生态位随着需求变化的此消彼长，而不是同一个生态位内部暴烈地替换。这种此消彼长就意味着，在整个更替的全过程，两种生态是高度亲和共存的，而且在很长一段时间内，原有生态位的体量会大得多。所以即使今天一台服务器内90%以上的价值是NVidia的产品，但服务器的常见形态仍然是2个“中央”处理器搭配8个“从属设备”GPU。这个形态实际上还是符合Intel的游戏规则，只不过“从属设备”这边的生态位已经远大于“中央”处理器的生态位了，大家买服务器更多是为了买这些“从属设备”，而且也尽量追求用更少的CPU来支持更多的“从属设备”。

实际上今天这种2CPU+8GPU这种看起来自然而然的形态也不是天然就该这样，而是老黄整个布局和执行的结果，Intel在这个过程处处给老黄挖坑，但奈何老黄对生态竞争逻辑的深刻理解以及十几年的布局。这个过程实际上要解决三个层级的问题：
第一个层级是芯片本身要足够好用，开发效率要足够高。实际上今天很多AI芯片的开发效率是远低于NVidia的CUDA+GPGPU的。这个层级也是无数AI芯片玩家至今没能迈过去的坎。
第二个层级是更进一步的要求，芯片不是一代产品，而是一个延续十几年，需要有持续生命力的体系。硬件层面能有延续数十年的持续性能提升空间，而且这个提升的速度要比竞争对手的更快，同时软件层面也不光是开发效率要高，在芯片持续演进的过程中，这种开发效率、兼容性要稳定平滑地延续几十代产品。
第三个层级就不光是纯技术问题了，毕竟生态是具有巨大惯性的，一个再好的方案如果游离于目前的主流形态太远，也很难克服生态巨大的惯性。同时，还需要足够好的需求来催化，因为生态位是由需求产生的。

整个这个阶段，老黄给我们演示了，和Intel的CPU竞争的最佳方式不是做另一种形态的CPU，而是在Intel的游戏规则下做大PCIe设备在加速计算领域的生态位。让这个生态位从CPU+PCIe扩展的体系下一个小的生态位逐渐增长为一个足够大的生态位，甚至超过CPU的生态位，进而吞噬Intel在数据中心的市场份额，甚至到今天可以拉着ARM试图把Intel从数据中心的AI解决方案中抹掉。	—— 提出新的解决方案，新的模式，新的体系，才可能取代现有的方案

生态的卡位靠的是开发者而不是业务。生态卡位最终目的是要让业务“不得不用”，但如果这个组件时直接服务最终业务的，那只能因为单纯的“好用”而用，但任何一个产品都有不好用的地方，很难真正意义上长期绑定，达不到“不得不用”的地步。实际上不得不用需要两层递进关系，也就是说在一个组件之上有大量“好用”的二次开发的组件，用户因为很多二次开发的组件“好用”，进而才能“不得不用”这些组件依赖的组件。这个层级递进越深，这种“不得不用”会越来越强烈。
我们看NVIDIA第三个阶段，借着深度学习的热潮是怎么布局自己的生态位的。他并不去抢深度学习框架的生态位，而是给各个造深度学习框架的开发者提供无微不至的服务，包括异常健全的文档，甚至连debug API这种估计很少有开发者会关注的文档都写得非常详细，也包括给很多开发者送显卡。当然最关键的，还是产品在这个生态位需求下的绝对竞争力。换句话讲，写深度学习框架的核心需求是让海量算法用户能简单获得极高的算力跑深度学习模型，AlexNet也证明了GPU比CPU快太多，因此对于做深度学习框架的开发者，支持GPU的框架显然也比只支持CPU的框架更具有竞争力，这就给了上面无数开发者最基础的动力去支持GPU，再加上事无巨细的文档和无微不至围绕开发者的一整套打法，自然海量开发者涌入CUDA体系，在CUDA之上写了无数的深度学习框架去竞争。上面开发者开发了不同特点的框架，每个最终用户都会其中一些框架的“好用”而加入某一阵营，但也因为所有框架基本都支持CUDA和NVidia的GPU，从而使得用户进入了“不得不用"CUDA和NVidia的GPU的状态。
这实际上做所有解决方案都绕不开的子集的思路，而大多数人做项目都不自觉会陷入做大而全的超集的思路。以NVidia的软件开发能力，在那个阶段去研发一个深度学习框架和TensorFlow、PyTorch包括早期的Caffe、theano竞争是完全没问题的，甚至可以借助软硬件协同的能力比各家的框架做得更有竞争力，甚至借此干掉其他框架。但NVidia实际上没有这么做，NVidia是一种典型的做子集的思路，做一个所有人都绕不开的子集。与之相对的是做一个大而全的超集的思路，这种思路是今天很多项目不自觉就会落入的思路，所有竞争对手有的所有好的特性我们也都支持，我们再做一些自己的特性，这样是一个功能比所有人更全的超集。实际上NVidia在下面看上面所有人卷超集，各个超集都把自己的CUDA纳入其中，间接促成了自己成为所有人绕不开的子集的目的。

解决方案式的打法是最后的收割阶段。实际上NVidia这几年才算真正开启了收割模式，如果你关注老黄这几年的演进，他会更多提到“重构计算机工作方式”，实际上这是向Intel发起冲锋了，今天的整个计算机系统实际上是围绕CPU定义的，围绕CPU定义了指令集、软件、以及繁荣的软硬件生态，老黄今天终于拿到了整个生态位里面最大的话语权。老黄借着三十年卧薪尝胆打下来的生态地位，开始真正对这个事实标准的体系进行重塑。这种重塑同样不是destructive的，无论有多大的话语权，生态的惯性仍然需要遵从。老黄更多把AI作为切入点，要在今天的计算机系统上支撑一个围绕AI的全新计算机系统，那么在AI领域拥有最大话语权的老黄自然也就可以将底层的经典计算机系统塑造成一个更适用于支撑上层新兴的AI计算机系统的底座。

当然对于生态竞争来讲，这种混乱和行业洗牌实际上是最大的生态竞争机遇。

NVidia另一个巨大的潜在隐患在于整套游戏规则没有给其他人空间。相比上一代裁判Intel而言，实际上Intel设计的游戏规则是分配了很多蛋糕给行业内其他赛道的，而NVidia这种几乎吃独食的方式，也给它在各个领域树立了无数竞争对手。这种模式在生态稳定的阶段可以拿到超额的利润，同样在危局之下同样也面临全行业甚至客户的敌对。

历史、考古、宗教、艺术、政治、军事、建筑、文学